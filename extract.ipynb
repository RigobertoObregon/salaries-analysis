{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y7/ggnbw41n3k1b9q1_qvcm5_9r0000gp/T/ipykernel_81100/89230367.py:17: SADeprecationWarning: The AutomapBase.prepare.reflect parameter is deprecated and will be removed in a future release.  Reflection is enabled when AutomapBase.prepare.autoload_with is passed.\n",
      "  Base.prepare(engine, reflect=True)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, func\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import config\n",
    "\n",
    "# the `create_engine` function prepares a connection to the database\n",
    "engine = create_engine(connection)\n",
    "\n",
    "# this object will automatically map our db entity into a Python class\n",
    "Base = automap_base()\n",
    "\n",
    "# get db into automapper\n",
    "Base.prepare(engine, reflect=True)\n",
    "\n",
    "# save classes as variables, prepare classes\n",
    "jobs = Base.classes.jobs\n",
    "\n",
    "skills = Base.classes.skills\n",
    "\n",
    "salaries = Base.classes.salaries\n",
    "\n",
    "# query our database (pull data and save into objects)\n",
    "session = Session(engine)\n",
    "\n",
    "rows_jobs = session.query(jobs.id, jobs.title, jobs.company_name, \n",
    "                        jobs.location, jobs.via, jobs.extensions, jobs.posted_at, \n",
    "                        jobs.schedule_type, jobs.work_from_home, jobs.date_time).all()\n",
    "\n",
    "#create dataframe for jobs\n",
    "jobs_df = pd.DataFrame(rows_jobs, columns=[\"id\", \"title\", \"company_name\", \n",
    "                                            \"location\", \"via\", \"extensions\", \"posted_at\", \n",
    "                                            \"schedule_type\", \"work_from_home\", \"date_time\"])\n",
    "\n",
    "rows_skills = session.query(skills.id, skills.description_tokens).all()\n",
    "\n",
    "#create dataframe for skills\n",
    "skills_df = pd.DataFrame(rows_skills, columns=[\"id\", \"description_tokens\"])\n",
    "\n",
    "\n",
    "rows_salaries = session.query(salaries.id, salaries.salary_pay, salaries.salary_rate, \n",
    "                        salaries.salary_avg, salaries.salary_min, salaries.salary_max, \n",
    "                        salaries.salary_hourly, salaries.salary_yearly, salaries.salary_standardized).all()\n",
    "\n",
    "#create dataframe for salaries\n",
    "salaries_df = pd.DataFrame(rows_salaries, columns=[\"id\", \"salary_pay\", \"salary_rate\", \n",
    "                                        \"salary_avg\", \"salary_min\", \"salary_max\", \n",
    "                                        \"salary_hourly\", \"salary_yearly\", \"salary_standardized\"])\n",
    "\n",
    "\n",
    "#join the 3 tables to a dataframe\n",
    "result_df = jobs_df.join(skills_df, lsuffix='_jobs', rsuffix='_skills').join(salaries_df, lsuffix='_', rsuffix='_salaries')\n",
    "\n",
    "\n",
    "#####################\n",
    "#DATA IN RESULTING CSV FILE SEEM TO HAVE ERROR IN 5 LINES, BAD COLUMN DATA\n",
    "#write the content of the dataframe to data folder and jobs_info.csv file\n",
    "#result_df.to_csv(\"./data/jobs_info.csv\")\n",
    "#####################\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
